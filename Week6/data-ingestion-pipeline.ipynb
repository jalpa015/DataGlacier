{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas dask and numpy\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import time\n",
    "import modin.pandas as mpd\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dataframe:  Dask DataFrame Structure:\n",
      "                   Id UserId AchievementType   Tier TierAchievementDate Points CurrentRanking HighestRanking TotalGold TotalSilver TotalBronze\n",
      "npartitions=49                                                                                                                                \n",
      "                int64  int64          object  int64              object  int64        float64        float64     int64       int64       int64\n",
      "                  ...    ...             ...    ...                 ...    ...            ...            ...       ...         ...         ...\n",
      "...               ...    ...             ...    ...                 ...    ...            ...            ...       ...         ...         ...\n",
      "                  ...    ...             ...    ...                 ...    ...            ...            ...       ...         ...         ...\n",
      "                  ...    ...             ...    ...                 ...    ...            ...            ...       ...         ...         ...\n",
      "Dask Name: read-csv, 49 tasks\n",
      "Dask time:  0.02496337890625\n"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "start_dask = time.time()\n",
    "df = dd.read_csv('./data/UserAchievements.csv')\n",
    "print(\"Dask dataframe: \", df)\n",
    "dask_time = time.time() - start_dask\n",
    "print(\"Dask time: \", dask_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataframe:                   Id    UserId AchievementType  Tier TierAchievementDate  \\\n",
      "0           3739822         1      Discussion     1          11/06/2019   \n",
      "1           3916402         1    Competitions     1          11/06/2019   \n",
      "2           3739823       368    Competitions     1          07/15/2016   \n",
      "3           3739824       368         Scripts     2          09/21/2016   \n",
      "4           3739825       368      Discussion     2          08/30/2016   \n",
      "...             ...       ...             ...   ...                 ...   \n",
      "42871159  173261487  11652940    Competitions     0          09/20/2022   \n",
      "42871160  173261488  11652941        Datasets     0          09/20/2022   \n",
      "42871161  173261489  11652941      Discussion     0          09/20/2022   \n",
      "42871162  173261490  11652941         Scripts     0          09/20/2022   \n",
      "42871163  173261491  11652941    Competitions     0          09/20/2022   \n",
      "\n",
      "          Points  CurrentRanking  HighestRanking  TotalGold  TotalSilver  \\\n",
      "0              0             NaN             3.0          0            0   \n",
      "1              0             NaN             NaN          0            0   \n",
      "2            204             NaN            75.0          0            0   \n",
      "3             40          2301.0          2005.0          0            3   \n",
      "4            212           344.0           319.0         14           13   \n",
      "...          ...             ...             ...        ...          ...   \n",
      "42871159       0             NaN             NaN          0            0   \n",
      "42871160       0             NaN             NaN          0            0   \n",
      "42871161       0             NaN             NaN          0            0   \n",
      "42871162       0             NaN             NaN          0            0   \n",
      "42871163       0             NaN             NaN          0            0   \n",
      "\n",
      "          TotalBronze  \n",
      "0                  14  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                  13  \n",
      "4                 139  \n",
      "...               ...  \n",
      "42871159            0  \n",
      "42871160            0  \n",
      "42871161            0  \n",
      "42871162            0  \n",
      "42871163            0  \n",
      "\n",
      "[42871164 rows x 11 columns]\n",
      "Pandas time:  36.32085371017456\n"
     ]
    }
   ],
   "source": [
    "# Import the data with pandas\n",
    "start_pandas = time.time()\n",
    "df = pd.read_csv('./data/UserAchievements.csv')\n",
    "print(\"Pandas dataframe: \", df)\n",
    "pandas_time = time.time() - start_pandas\n",
    "print(\"Pandas time: \", pandas_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 21:42:43,201\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.7.7</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.7.7', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:57873', 'raylet_socket_name': 'tcp://127.0.0.1:54627', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\pjalp\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-10-01_21-42-38_469647_15564', 'metrics_export_port': 55174, 'gcs_address': '127.0.0.1:61014', 'address': '127.0.0.1:61014', 'dashboard_agent_listen_port': 52365, 'node_id': 'a275027287919c4c69248a2ac994549fce977a76cea444f7d2ef9b4d'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data with ray\n",
    "start_ray = time.time()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 21:42:47,087\tWARNING read_api.py:281 -- ⚠️  The blocks of this dataset are estimated to be 5.0x larger than the target block size of 512 MiB. This may lead to out-of-memory errors during processing. Consider reducing the size of input files or using `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray dataframe:  Dataset(num_blocks=1, num_rows=42871164, schema={Id: int64, UserId: int64, AchievementType: string, Tier: int64, TierAchievementDate: string, Points: int64, CurrentRanking: int64, HighestRanking: int64, TotalGold: int64, TotalSilver: int64, TotalBronze: int64})\n",
      "Ray time:  53.74173331260681\n"
     ]
    }
   ],
   "source": [
    "df = ray.data.read_csv('./data/UserAchievements.csv')\n",
    "print(\"Ray dataframe: \", df)\n",
    "ray_time = time.time() - start_ray\n",
    "print(\"Ray time: \", ray_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "################\n",
    "# File Reading #\n",
    "################\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: UserAchievments\n",
    "file_name: UserAchievments\n",
    "table_name: UserAchievments\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - Id\n",
    "    - UserId\n",
    "    - AchievementType\n",
    "    - Tier\n",
    "    - TierAchievementDate\n",
    "    - Points\n",
    "    - CurrentRanking\n",
    "    - HighestRanking\n",
    "    - TotalGold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file\n",
    "import testutility as tu\n",
    "config = tu.read_config_file('file.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UserAchievments'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'UserAchievments',\n",
       " 'file_name': 'UserAchievments',\n",
       " 'table_name': 'UserAchievments',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['Id',\n",
       "  'UserId',\n",
       "  'AchievementType',\n",
       "  'Tier',\n",
       "  'TierAchievementDate',\n",
       "  'Points',\n",
       "  'CurrentRanking',\n",
       "  'HighestRanking',\n",
       "  'TotalGold']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data with config file\n",
    "df = pd.read_csv('./data/UserAchievements.csv', delimiter = config['inbound_delimiter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation failed\n",
      "Following File columns are not in the YAML file ['totalsilver', 'totalbronze']\n",
      "Following YAML columns are not in the file uploaded []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate column names\n",
    "tu.col_header_val(df,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame Column:  Index(['id', 'userid', 'achievementtype', 'tier', 'tierachievementdate',\n",
      "       'points', 'currentranking', 'highestranking', 'totalgold',\n",
      "       'totalsilver', 'totalbronze'],\n",
      "      dtype='object')\n",
      "columns from YAML config file:  ['Id', 'UserId', 'AchievementType', 'Tier', 'TierAchievementDate', 'Points', 'CurrentRanking', 'HighestRanking', 'TotalGold']\n"
     ]
    }
   ],
   "source": [
    "print(\"Data frame Column: \",df.columns)\n",
    "print(\"columns from YAML config file: \",config['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest time is:  dask_time  and it took:  0.02496337890625\n",
      "The maximum time is:  ray_time  and it took:  53.74173331260681\n"
     ]
    }
   ],
   "source": [
    "# add time variables to dictionary variable\n",
    "time_dict = {'dask_time': dask_time, 'pandas_time': pandas_time, 'ray_time': ray_time}\n",
    "\n",
    "# lowest time\n",
    "min_time = min(time_dict, key=time_dict.get)\n",
    "# print the lowest time and the time it took\n",
    "print(\"The lowest time is: \", min_time, \" and it took: \", time_dict[min_time])\n",
    "maximum_time = max(time_dict, key=time_dict.get)\n",
    "print(\"The maximum time is: \", maximum_time, \" and it took: \", time_dict[maximum_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask time:  0.02496337890625\n",
      "Pandas time:  36.32085371017456\n",
      "Ray time:  53.74173331260681\n"
     ]
    }
   ],
   "source": [
    "#print the time it took for each\n",
    "print(\"Dask time: \", dask_time)\n",
    "print(\"Pandas time: \", pandas_time)\n",
    "print(\"Ray time: \", ray_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('DataGlacier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3f1417e7a1067bcaabea974b0272df39b7b7acc6aa137b9d22ada4819379953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
